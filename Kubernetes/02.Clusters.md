# single-node cluster with Minikube
在创建集群之前，有一些先决条件需要安装。这些包括VirtualBox，Kubernetes的kubectl，还有Minikube。
我们将以管理员模式使用PowerShell并在PowerShell配置文件中添加了以下别名和函数：
```PowerShell
Set-Alias -Name k -Value kubectl

function mk
{
minikube-windows-amd64 `
--show-libmachine-logs `
--alsologtostderr      `
@args
}
```
```
> mk version
minikube version: v0.12.2
> k version
Client Version: version.Info{Major:"1", Minor:"4", ...}
```
## Creating the cluster
我们使用start命令并指定v1.4.3版本来创建集群:
```
> mk start --kubernetes-version="v1.4.3"
```
这需要一段时间，因为Minikube可能需要下载image并设置本地集群。
现在回顾一下Minikube做了什么：
* 创建一个VirtualBOx VM
* 设置boot2docker
* 为本地计算机和VM创建证书
* 在本地计算机和虚拟机之间建立网络
* 在VM上运行本地Kubernetes集群
## Checking out the cluster
让我们ssh进入虚拟机：
```bash
> mk ssh
> k cluster-info
> k get nodes
NAME       STATUS    AGE
minikube   Ready     8h
> k run echo --image=gcr.io/google_containers/echoserver:1.4 --port=8080
deployment "echo" created
# Kubernetes创建了一个deployment，我们有一个pod正在运行
> k get pods
NAME                    READY     STATUS    RESTARTS   AGE
echo-3580479493-cnfn1   1/1       Running   0          2m
# 将Pod作为服务暴露出来
> k expose deployment echo --type=NodePort
# 将服务暴露为类型NodePort意味着它暴露给主机的某个端口。但它不是我们运行该pod的8080端口。端口被映射到集群中。要访问该服务，我们需要集群IP和暴露端口。
> mk ip
192.168.99.100
> k get service echo --output='jsonpath="{.spec.ports[0].NodePort}"'
32041
> curl http://192.168.99.100:32041/hi
```
## the cluster dashboard
Kubernetes有一个漂亮的网络界面，这是作为一个pod中的服务部署的。仪表板可提供集群的概括，还有各个资源细节，查看日志，编辑资源文件等，是当你想手动检查集群时最好的武器。要启动它，请输入minikube dashboard。
# multi-node cluster using kubeadm
Kubeadm运行预先配置的硬件（物理或虚拟的）。在创建Kubernetes集群之前，我们需要准备一些虚拟机并安装基本软件，例如docker，kubelet，kubeadm和kubectl（仅在主服务器上需要）。
## Preparing a cluster of vagrant VMs
以下vagrant文件将创建一个名为n1，n2，n3和n4的四个虚拟机集群。它基于Ubuntu-16.04。
```ruby
# -*- mode: ruby -*-
# vi: set ft=ruby :
hosts = {
  "n1" => "192.168.77.10",
  "n2" => "192.168.77.11",
  "n3" => "192.168.77.12",
  "n4" => "192.168.77.13"
}
Vagrant.configure("2") do |config|
  # always use Vagrants insecure key
  config.ssh.insert_key = false
  # forward ssh agent to easily ssh into the different machines
  config.ssh.forward_agent = true
  check_guest_additions = false
  functional_vboxsf     = false
  config.vm.box = "bento/ubuntu-16.04"
 hosts.each do |name, ip|
    config.vm.define name do |machine|
      machine.vm.network :private_network, ip: ip
      machine.vm.provider "virtualbox" do |v|
        v.name = name
      end
    end
  end
end
```
## Installing the required software
```
> vagrant ssh v4
vagrant@vagrant:~$ sudo apt-get install python-pip
vagrant@vagrant:~$ sudo pip install ansible
vagrant@vagrant:~/ansible$ ansible --version
ansible 2.1.2.0
```
我们创建一个名为ansible的目录，并在其中放入三个文件：hosts，vars.yml和playbook.yml。
#### The hosts file
这是inventory文件，它告诉ansible在什么主机上操作。主机必须可以通过controller主机进行SSH访问。
```
[all]
192.168.77.10
192.168.77.11
192.1680.77.12
```
#### The vars.yml file
vars.yml文件只保留我想要在每个节点上安装的软件包列表。
```
---
PACKAGES:
  - vim
  - htop
  - tmux
  - docker.io
  - kubelet
  - kubeadm
  - kubectl
  - kubernetes-cni
```
#### The playbook.yml file
你可以使用playbook.yml文件来在所有主机上安装软件包：
```
---
- hosts: all
  become: true
vars_files:
  - vars.yml
strategy: free
tasks:
  - name: Add the Google signing key
    apt_key: url=https://packages.cloud.google.com/apt/doc/apt-key.gpg
    state=present
  - name: Add the k8s APT repo
    apt_repository: repo='deb http://apt.kubernetes.io/ kubernetes-
    xenial main' state=present
  - name: Install packages
    apt: name={{ item }} state=installed update_cache=true force=yes
    with_items: "{{ PACKAGES }}"
```
然后运行：
```
ansible-playbook -i hosts playbook.yml
```
## Creating the cluster
我们在n1（192.168.77.10）上初始化master。
#### Initializing the master
```
vagrant@vagrant:~$ sudo kubeadm init --api-advertise-addresses 192.168.77.10
```
你现在可以通过在每个节点上运行以下命令来加入任意数量的计算机：
```
kubeadm join --token cca1f6.e87ed55d46d00d91 192.168.77.10
```
## Setting up the pod network
pods要相互交谈，这需要一个pod网络插件，由kubeadm生成的集群需要基于CNI的插件。在master虚拟机上运行以下命令：
```
vagrant@vagrant:~$ kubectl create -f https://git.io/weave-kube
vagrant@vagrant:~$ daemonset "weave-net" created
vagrant@vagrant:~$ kubectl get po --all-namespaces
```
## Adding the worker nodes
我们可以使用我们之前获得的token将worker节点添加到集群中。在每个节点上运行以下命令：
```
sudo kubeadm join --token cca1f6.e87ed55d46d00d91 192.168.77.10
```
# clusters in the cloud
Kubernetes具有云提供者接口的概念。每个云提供商可以实现这个接口，然后托管Kubernetes。
## The cloud-provider interface
云提供者接口是Go数据类型和接口的集合。它被定义为一个叫做cloud.go的文件：
```Go
type Interface interface {
    LoadBalancer() (LoadBalancer, bool)
    Instances() (Instances, bool)
    Zones() (Zones, bool)
    Clusters() (Clusters, bool)
    Routes() (Routes, bool)
    ProviderName() string
    ScrubDNS(nameservers, searches []string) (nsOut, srchOut []string)
}
```
Kubernetes根据instances, Zones, Clusters和Routes进行操作，并且还需要访问load balancer和provider name。ScrubDNS（）是唯一的底层方法。所有主要方法都会返回其他接口。
```Go
type Clusters interface {
    ListClusters() ([]string, error)
    Master(clusterName string) (string, error)
}
```
ListClusters（）方法返回集群名称。Master（）方法返回主节点的IP地址或DNS名称。
## GCP
Google Cloud Platform（GCP）是唯一支持Kubernetes的云提供商。Google Kubernetes引擎（GKE）是一个基于Kubernetes的容器管理解决方案。
## AWS
AWS拥有自己的称为ECS的容器管理服务，但它不基于Kubernetes。你可以很好地在AWS上运行Kubernetes。它是一个受支持的提供商，并且有很多关于如何设置它的文档。
Kops支持以下功能：
* 自动化Kubernetes集群云（AWS）CRUD
* 高可用性（HA）Kubernetes集群
* 使用状态同步模型进行dry-run和automatic idempotency
* 自定义支持kubectl附加组件
* Kops可以生成Terraform配置
* 基于目录树中定义的简单元模型
* 简单的命令行语法
要创建群集，你需要通过route53执行一些DNS配置，设置一个S3存储区来存储集群配置，然后运行一个命令：
```
kops create cluster --cloud=aws --zones=us-east-1c ${NAME}
```
## Azure
Azure也有自己的容器管理服务。你可以使用基于Mesos的DC/OS或Docker Swarm来管理它们。但是你也可以使用Kubernetes。你可以使用kubeadm创建Kubernetes集群。但推荐使用kubernetes-anywhere，它提供跨平台的方式在云环境中创建集群（至少包括GCP，AWS和Azure）。

你需要安装Docker，make和kubectl，当然还有你的Azure订阅ID。然后你克隆kubernetes-anywhere，运行几个make命令，你的集群就准备好了。
# bare-metal cluster
以下是bare-metal的用例：
* 价格：如果你已经管理大型裸机集群，在你的物理基础设施上运行Kubernetes集群可能便宜得多
* 较低的网络延迟：如果节点之间的延迟时间必须较短，则虚拟机开销可能太大
* 监管要求：如果你必须遵守规定，可能不被允许使用云提供商
* 你希望完全控制硬件：云提供商提供了多种选择，但你可能有特殊需求
