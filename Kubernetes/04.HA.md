# High-availability concepts
## Redundancy
冗余是硬件和数据级别的可靠且高度可用的系统的基础。如果关键组件发生故障并且希望系统继续运行，则必须准备好另一个相同的组件。Kubernetes本身通过replication controllers和replica sets来处理无状态的Pod。但是，当某些组件发生故障时，etcd中的集群状态和主组件本身需要冗余功能。另外，如果系统的组件不由冗余存储备份（例如，在云平台上），则需要添加冗余以防止数据丢失。
## Hot swapping
热插拔是指在不让系统不可访问的情况下更换故障组件的概念，对用户的干扰最小（理想情况下为零）。如果组件是无状态的（或其状态存储在单独的冗余存储中），则热交换新组件以替换它很容易，只需将所有客户端重定向到新组件。但是，如果它存储本地状态，包括内存中，那么热交换并不那么容易。有两个主要选项：
* 放弃正在进行的交易
* 保持热副本同步

第一个解决方案要简单得多。大多数系统都具有足够的弹性来应对故障。客户端可以重试失败的请求，热交换后的组件将为它们提供服务。
第二个解决方案更加复杂和脆弱，并且会产生性能开销，因为每个交互都必须复制到两个副本（并确认）。但这对某些系统可能是必需的。
## Leader election
Leader或master选举是分布式系统中的常见模式。你拥有多个相同的组件来协作和共享负载，但是选择一个组件作为Leader，并通过Leader将某些操作序列化。你可以将带有Leader选举的分布式系统视为冗余和热交换的组合。这些组件都是冗余的，当当前Leader失败或变得不可用时，选出新Leader并热插拔。
## Smart load balancing
负载平衡是关于将工作负载分布在多个处理传入请求的组件上。当某些组件出问题，负载均衡器必须首先停止向失败或无法访问的组件发送请求。第二步是配置新组件以恢复容量并更新负载均衡器。Kubernetes通过services, endpoints和labels对此提供了很好的支持。
## Idempotency
许多类型的失败可能是暂时的。这在网络问题或过于严格的超时中最为常见。不响应健康检查的组件将被视为无法访问，另一个组件将取代它。原本规划在发生故障的组件上的工作可能会发送给其他组件。但是原始组件可能仍在工作并完成相同的工作。最终的结果是可能会执行两次相同的工作。避免这种情况是非常困难的， 要支持exactly-once语义，你需要在开销，性能，延迟和复杂性方面付出沉重的代价。因此大多数系统选择支持at-least-once语义，这意味着可以多次执行相同的工作。这个属性被称为幂等性。如果多次执行相同的操作，幂等系统会保持其状态。
## Self-healing
当动态系统中出现组件故障时，通常需要系统能够自我修复。Kubernetesreplication controllers和replica sets是自我修复系统的很好例子。但是失败可以远远超出pod。remedy控制器是自我修复概念的一个很好的例子。自我修复从自动检测问题开始，然后进行自动化解决。配额和限制有助于检查和平衡，以确保自动化自我修复不会因DDOS攻击等不可预测的情况而受到冲击。
# High-availability best practices
## Creating highly available clusters
要创建高度可用的Kubernetes集群，master组件必须是冗余的。这意味着etcd必须作为一个集群进行部署（通常跨三个或五个节点），并且Kubernetes API服务器必须是冗余的。如有必要，辅助集群管理服务（如Heapster的存储）也可以进行冗余部署。
## Making your nodes reliable
节点会失败，或者某些组件会失败，但许多失败是暂时的。基本的保证是确保Docker Daemon和kubelet在发生故障时自动重启。如果运行基于Debian的现代操作系统CoreOS（包括Ubuntu> = 16.04）或任何其他使用systemd作为init机制的操作系统，那么将Docker和kubelet部署为自启动守护进程很容易：
```bash
systemctl enable docker
systemctl enable kublet
```
对于其他操作系统，Kubernetes项目选择monit来实现高可用性。
## Protecting cluster state
Kubernetes集群状态存储在etcd中。etcd集群被设计为超级可靠并分布在多个节点上。利用这些功能获得可靠且高度可用的Kubernetes集群非常重要。
#### Clustering etcd
你的etcd集群中至少应有三个节点。如果你需要更高的可靠性和冗余度，你可以选择七个或其他奇数个节点。在网络分裂的情况下，节点的数量必须是奇数才能占多数。为了创建一个集群，etcd节点应该能够发现彼此。
#### Static discovery
使用静态发现，你可以直接管理每个etcd的IP地址/主机名。这并不意味着你管理Kubernetes集群外部的etcd集群，或者负责保持etcd集群健康。etcd节点将作为pod运行并在需要时自动重新启动。

每个节点将收到此初始集群信息作为命令行信息：
```
--initial-cluster etcd-1=http://10.0.0.1:2380,etcd-2=http://10.0.0.2:2380,etcd-3=http://10.0.0.3:2380
--initial-cluster-state new
```
或者它会将其作为环境变量接收：
```
ETCD_INITIAL_CLUSTER="etcd-1=http://10.0.0.1:2380,etcd-2=http://10.0.0.2:2380,etcd-3=http://10.0.0.3:2380"
ETCD_INITIAL_CLUSTER_STATE=new
```
#### Etcd discovery
通过使用etcd discovery，你可以使用现有集群让新集群的节点相互发现。当然，这需要新的集群节点有权访问现有的集群。请注意，发现仅与初始化集群时的初始引导相关。一旦集群启动并与初始节点一起运行，从正在运行的集群添加和删除节点将使用单独的协议完成，因此不必维护对公共etcd发现服务的永久依赖。
#### DNS discovery
发现也可以使用DNS SRV记录实现（使用或不使用TLS）。
#### The etcd.yaml file
根据发现方法不同，在每个节点上启动etcd实例的命令在etcd.yaml pod清单中稍有不同。清单应该复制到每个ectd节点中的/etc/kubernetes/manifests。
#### Verifying the etcd cluster
一旦etcd集群启动并运行，你可以访问etcdctl工具来检查集群状态和运行状况。Kubernetes允许你通过exec命令直接在pod或容器中执行命令：
```
etcdctl member list
etcdctl cluster-health
etcdctl set test
etcdctl get test
```
## Protecting data
保护集群状态和配置非常好，但更重要的是保护你自己的数据。如果集群状态损坏了，你可以从头开始重建集群（尽管在重建期间该集群将不可用）。但是如果你自己的数据被破坏或丢失了，你就陷入了困境。冗余是王道。但Kubernetes集群状态是非常动态的，你的大部分数据可能不那么动态。例如，许多历史数据通常很重要，可以进行备份和恢复。实时数据可能会丢失，但整个系统可能会恢复到较早的快照并且只会受到暂时的损害。
## Running redundant API servers
API服务器是无状态的，可以从etcd集群获取所有必要的数据。这意味着你可以轻松运行多个API服务器，而无需在它们之间进行协调。一旦你有多个API服务器运行，你可以在它们前面放置一个负载均衡器，使其对客户端透明。
## Running leader election with Kubernetes
某些主组件（如scheduler和controller manager）不能同时激活多个实例，否则将是混乱的，因为多个调度程序尝试将同一个pod安排到多个节点或多次放入同一个节点。拥有高度可扩展的Kubernetes集群的正确方法是让这些组件以领导选举模式运行。这意味着多个实例正在运行，但是一次只有一个实例处于活动状态，如果失败，另一个实例将被选为领导者并取而代之。

Kubernetes通过--leader-elect flag支持这种模式。scheduler和controller manager可以通过将它们各自的manifest复制到/etc/kubernetes/manifests来部署为pod。
* a snippet from a scheduler manifest
```YAML
- command:
  - /bin/sh
  - -c
  - /usr/local/bin/kube-scheduler --master=127.0.0.1:8080 --v=2 --leader-elect=true 1>>/var/log/kube-scheduler.log 2>&1
```
* a snippet from a controller manager manifest
```YAML
- command:
  - /bin/sh
  - -c
  - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce --service-account-private-key-file=/srv/kubernetes/server.key --v=2 --leader-elect=true 1>>/var/log/kube-controller-manager.log 2>&1
```
请注意，这些组件不可能像其他Pod一样由Kubernetes自动重新启动，因为这些组件是负责重新启动失败Pod的Kubernetes组件，因此如果它们失败，它们将无法自己重新启动。必须有一个准备好的替代品已经在运行。
#### Leader election for your application
领导人选举对于你的应用也是非常有用的，但是实施起来却非常困难。幸运的是，Kubernetes有一个leader-elector容器来支持你的应用的领导人选举。基本原理是将Kubernetes endpoints与ResourceVersion和Annotations结合使用。当你将这个容器作为应用程序pod中的sidecar关联时，你将以非常精简的方式获得领导者选举功能。
## Making your staging environment highly available
高可用性不是那么简单的设置。你需要在将其部署到生产环境之前测试可靠且高度可用的集群。理论上，对集群的任何更改都可能会破坏高可用性，而不会中断其他集群功能。重点是，就像其他任何事情一样，如果你不测试它，假设它不能工作。测试可靠性和高可用性最好的方法是创建一个临时环境，让它尽可能地复制你的生产环境。
## Testing high-availability
测试高可用性需要详细计划和深入理解你的系统。每个测试的目标都是揭示系统设计或实现中的缺陷，并提供足够的覆盖范围，如果测试通过，你可以认为系统的行为与预期相同。

在可靠性和高可用性方面，这意味着你需要找出方法来打破系统并观察它重新组合起来。
* Comprehensive list of possible failures (including reasonable combinations)
* For each possible failure, it should be clear how the system should respond
* A way to induce the failure
* A way to observe how the system reacts

# Live cluster upgrades
运行Kubernetes集群涉及的最复杂和最危险的任务之一是实时升级。不同版本系统的不同部分之间的相互作用往往很难预测，但在许多情况下，这是必需的。有许多用户的大型集群不能为了维护系统而离线。攻击复杂性的最好方法是分而治之。微服务架构在这方面很有帮助。你永远不会升级你的整个系统。你只是不断升级几套相关的微服务。正确设计的升级将保持向后兼容性，至少是在所有客户端都升级之前，然后在几个发行版本中弃用旧的API。
## Rolling upgrades
滚动升级是指在升级中逐步将组件从当前版本升级到下一版本。这意味着你的集群将同时运行当前和新组件。这里有两种情况需要考虑：
* 新组件向后兼容
* 新组件不向后兼容

如果新组件向后兼容，那么升级应该非常容易。
```YAML
apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    name: nginx-deployment
  spec:
    replicas: 3
    template:
      metadata:
        labels:
          app: nginx
      spec:
        containers:
        - name: nginx
          image: nginx:1.7.9
          ports:
          - containerPort: 80
```
要开始滚动更新，请创建deployment资源：
```
$ kubectl create -f nginx-deployment.yaml --record
$ kubectl rollout status deployment/nginx-deployment
```
当你只想升级一个pod时，deployment资源非常棒，但你可能经常需要升级多个pod，而这些pod有时具有版本相互依赖关系。在这些情况下，你有时必须放弃滚动更新或引入临时兼容性层。例如，假设服务A依赖于服务B，服务B现在有一个重大变化。服务A的v1 pod不能与服务B v2的pod交互操作。从可靠性和变更管理的角度来看，让服务B v2 pod支持旧的和新的API也是不可取的。在这种情况下，解决方案可能是引入实现B服务v1 API的适配器服务。此服务将位于A和B之间，并将跨各种版本翻译请求和响应。这增加了部署过程的复杂性并需要几个步骤，但好处是A和B服务本身很简单。你可以跨不兼容的版本执行滚动更新，一旦所有人都升级到v2（所有A Pod和所有B Pod），所有适配器可以拿掉。
## Blue-green upgrades
滚动更新非常适合高可用性，但有时涉及管理正确滚动更新的复杂性被认为太高，或者增加了大量工作来推动更重要的项目。在这些情况下，蓝绿色升级提供了一个很好的选择。通过蓝绿色版本，你可以使用新版本准备完整的生产环境副本。现在你有两个副本，旧的（蓝色）和新的（绿色）。无论哪一个是蓝色的，哪一个是绿色的并不重要。重要的是你有两个完全独立的生产环境。目前，蓝色处于活动状态并处理所有请求。你可以用绿色运行所有的测试。一旦测试通过，你启动开关，绿色变得活跃。如果出现问题，回滚就很容易，只需从绿色切换回蓝色。这里忽略了存储和内存状态。这个开关假定蓝色和绿色只由无状态组件组成，并共享一个公共持久层。
## Managing data-contract changes
数据合同描述了数据的组织方式。这是结构元数据的一个统称。数据库schema是最典型的例子。最常见的例子是关系数据库schema。如果你有一个配置文件，这个配置文件有一个file格式（JSON，YAML，XML）和一些描述层次结构，键，值和数据类型的内部结构。无论如何，你需要仔细管理它，否则当读取，解析或验证的代码遇到不熟悉的结构的数据时，你会得到运行时错误。
## Deprecating APIs
API弃用有两个部分：内部和外部。内部API是由你的团队或组织完全控制的组件使用的API。你可以确定所有的API用户都会在短时间内升级到新的API。外部API由你的直接影响范围之外的用户或服务使用。在灰色地带的情况下，你为一个庞大的组织工作，甚至可能需要将内部API视为外部API。如果你有很多用户（或几个非常重要的用户）使用你的API，你应该仔细考虑弃用。弃用API意味着强制用户更改其应用程序或被锁定到较早版本。
有几种方法可以减轻疼痛：
* 不要弃用。扩展现有API或保持以前的API处于活动状态。它有时非常简单，但它增加了测试负担。
* 为你的所有相关应用提供客户端库。这是一个很好的做法，它允许你在不中断用户的情况下对底层API进行许多更改。
* 如果不得不弃用，请解释原因，为用户提供足够的时间进行升级，并提供尽可能多的支持（例如，带有示例的升级指南）。
# Large-cluster design trade-offs
## Availability requirements
不同的系统对可靠性和可用性的要求非常不同。而且不同的子系统有着非常不同的要求。例如，计费系统一直是高优先级的，因为如果计费系统停机，你无法赚钱。但是，即使在计费系统中，如果分账单收费的功能有时不可用，从业务角度来看也可能没问题。
## Best effort
尽最大努力意味着没有保证。如果它能正常工作，很好，如果它不起作用，好吧。这种可靠性和可用性水平可能适用于经常变化的内部组件，并且努力使它们变得健壮并不值得。对于对外公布的服务也可能适用于测试版。

在Kubernetes背景下，最大的问题是集群提供的所有服务是否是best effort。如果是这种情况，那么集群本身不必高度可用。你可能只有一个主节点和一个单一的etcd实例，而Heapster或其他监控解决方案可能不需要部署。
## Maintenance windows
在具有维护窗口的系统中，有特殊时间专门用于执行各种维护活动，例如应用安全补丁，升级软件，清理日志文件和数据库清理。通过维护窗口，系统（或子系统）变得不可用。这是计划的离线时间，并且通常会通知用户。维护窗口的好处在于，你不必担心维护操作如何与进入系统的实时请求进行交互。它可以极大地简化操作。系统管理员喜欢维护窗口，就像开发人员喜欢best effort系统一样。当然，不利的一面是系统在维护期间停机。只有用户活动受限于特定时间的系统才可以接受。

使用Kubernetes，你可以通过负载平衡将所有传入请求重定向到网页（或JSON响应），以便通知用户有关维护窗口的信息，从而实现维护窗口。但在大多数情况下，Kubernetes的灵活性应该允许你进行实时维护。
## Quick recovery
快速恢复是高度可用集群的另一个重要方面。有时东西会出错，此时你的不可用时钟开始运行。你多快能恢复正常？有时候这不取决于你。快速恢复最快的当然是蓝绿色的部署，如果在发现问题时保持以前的版本运行。另一方面，滚动更新意味着如果问题发现得早，那么大多数的pod仍然运行以前的版本。即使你的备份是最新的并且你的恢复过程确实有效，与数据相关的问题也需要很长时间才能恢复。
## Zero-downtime
终于我们来到零停机时间系统。零停机时间系统是不可能的。所有系统都会发生故障，所有软件系统都会发生故障。有时候，这种失败已经足够严重，导致系统或其某些服务将会停止运行。将零停机时间看作是尽力而为的分布式系统设计。你可以设计零停机时间，因为你可以提供大量冗余和机制来解决预期的故障，而不会导致系统停机。请记住，即使存在零停机时间的案例，也并不意味着每个组件都必须是。

零停机计划如下：
* 在每个级别冗余
* 自动热插拔故障组件
* 大量的监测和警报以便能够及早发现问题
* 在部署到生产之前进行大量的测试
* 保留原始数据
* 可接受的正常运行时间是最后的手段 （系统降级服务）
## Performance and data consistency
当你开发或运行分布式系统时，CAP定理应该始终处于你的脑海中。我们重点介绍了高可用性系统，这意味着AP。为了实现高可用性，我们必须牺牲一致性。但这并不意味着我们的系统将有损坏的或任意数据。最终的一致性是关键。我们的系统可能会稍微落后并提供访问权限给有点陈旧的数据，但最终你会得到你所期望的。当你开始考虑最终一致性时，它会为潜在显着的性能改进打开大门。